{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dp\n",
    "from dp import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read and Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_TRAIN_1K))\n",
    "\n",
    "sentences = ds.sentences_from_splits(df_splits, test_sentence = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[token_id:1 | form:Ms. | lemma:ms. | pos:NNP | xpos:_ | morph:_ | head:2 | relation:NMOD,\n",
       " token_id:2 | form:Haag | lemma:haag | pos:NNP | xpos:_ | morph:_ | head:3 | relation:SBJ,\n",
       " token_id:3 | form:plays | lemma:play | pos:VBZ | xpos:_ | morph:_ | head:0 | relation:ROOT,\n",
       " token_id:4 | form:Elianti | lemma:elianti | pos:NNP | xpos:_ | morph:_ | head:3 | relation:OBJ,\n",
       " token_id:5 | form:. | lemma:. | pos:. | xpos:_ | morph:_ | head:3 | relation:P]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2 -> 1, 3 -> 2, 0 -> 3, 3 -> 4, 3 -> 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1].to_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_id:1 | form:In | lemma:in | pos:IN | xpos:_ | morph:_ | head:43 | relation:ADV"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][0] #first token of first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_id:1 | form:In | lemma:in | pos:IN | xpos:_ | morph:_ | head:43 | relation:ADV"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0].tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_splits = ds.splits_from_sentences(sentences)\n",
    "\n",
    "# dummy_splits = []\n",
    "# for split in df_splits:\n",
    "#     split[\"dummy1\"] = \"_\"\n",
    "#     split[\"dummy2\"] = \"_\"\n",
    "#     dummy_splits.append(split)\n",
    "\n",
    "# dl.to_conll(dp.config.OUTPUT / Path(\"dummy.conll06\"), dummy_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eisner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_score = np.array([[-9999, 9, 10, 9], [np.inf, -9999, 20, 3], [np.inf, 30, -9999, 30], [np.inf,11,0 ,-9999]])\n",
    "no_tokens = 4\n",
    "\n",
    "eis = models.eisner.Eisner()\n",
    "eis.fit(no_tokens, ml_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.999e+03,  9.000e+00,  1.000e+01,  9.000e+00],\n",
       "       [       inf, -9.999e+03,  2.000e+01,  3.000e+00],\n",
       "       [       inf,  3.000e+01, -9.999e+03,  3.000e+01],\n",
       "       [       inf,  1.100e+01,  0.000e+00, -9.999e+03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eis.execute_backtrack(0, no_tokens-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'o_r': {(0, 1): 0, (1, 2): 1, (2, 3): 2, (0, 2): 0, (1, 3): 2, (0, 3): 0}, 'o_l': {(0, 1): 0, (1, 2): 1, (2, 3): 2, (0, 2): 0, (1, 3): 2, (0, 3): 2}, 'c_r': {(0, 1): 0, (1, 2): 1, (2, 3): 2, (0, 2): 0, (1, 3): 1, (0, 3): 0}, 'c_l': {(0, 1): 1, (1, 2): 2, (2, 3): 3, (0, 2): 2, (1, 3): 2, (0, 3): 2}})\n"
     ]
    }
   ],
   "source": [
    "print(eis.backtrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2 -> 3, 0 -> 2, 2 -> 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.core.Tree.from_eisner(sentences[1],eis.backtrack_execution_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = [0]\n",
    "buffer = list(range(1, 4))\n",
    "arcs = set()\n",
    "correct_arcs = set(((2,1), (2,3), (0,2)))\n",
    "# correct_arcs = set(((2,1), (2,3), (5,4),(2,5), (6,2), (8, 7), (6,8), (6,9), (0,6)))\n",
    "start_config = models.arc_standard.Configuration(stack, buffer, arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = models.arc_standard.Oracle(start_config, correct_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sequence, configs_sequence = o.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['shift', 'left', 'shift', 'right', 'right', 'shift'],\n",
       " [<dp.models.arc_standard.Configuration at 0x7fd15026a950>,\n",
       "  <dp.models.arc_standard.Configuration at 0x7fd15026a990>,\n",
       "  <dp.models.arc_standard.Configuration at 0x7fd15026aa10>,\n",
       "  <dp.models.arc_standard.Configuration at 0x7fd15026aa50>,\n",
       "  <dp.models.arc_standard.Configuration at 0x7fd15026aa90>,\n",
       "  <dp.models.arc_standard.Configuration at 0x7fd15026ab50>])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence, configs_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2), (2, 1), (2, 3)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs_sequence[-1].arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = [[0.3, 0.1, 0.6], [0.9, 0.05, 0.05],[0.2, 0.35, 0.45], [0.1, 0.2, 0.7], [0.1, 0.7, 0.2],[0.7, 0.1, 0.2]]  #[[left, right, shift]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcstand = models.arc_standard.ArcStandard(start_config, model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_config = arcstand.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2), (2, 1), (2, 3)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_config.arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_TRAIN_FULL))\n",
    "\n",
    "sentences = ds.sentences_from_splits(df_splits, test_sentence = False)\n",
    "trees = [s.to_tree() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential_trees = dp.core.make_potential_trees( sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentences[1]\n",
    "tree = trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = [0]\n",
    "buffer = list(range(1, len(tree.arcs)+1))\n",
    "arcs = set()\n",
    "correct_arcs = {(arc.head, arc.dep) for arc in tree.arcs}\n",
    "\n",
    "start_config = models.arc_standard.Configuration(stack, buffer, arcs)\n",
    "o = models.arc_standard.Oracle(start_config, correct_arcs)\n",
    "correct_sequence, configs_sequence = o.execute()\n",
    "\n",
    "# model_scores = [[0.3, 0.1, 0.6], [0.9, 0.05, 0.05],[0.2, 0.35, 0.45], [0.1, 0.2, 0.7], [0.1, 0.7, 0.2],[0.7, 0.1, 0.2]]  #[[left, right, shift]]\n",
    "# arcstand = models.arc_standard.ArcStandard(start_config, model_scores ,correct_sequence)\n",
    "# final_config = arcstand.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence, tree in zip(sentences, trees):\n",
    "#     stack = [0]\n",
    "#     buffer = list(range(1, len(sentence)+1))\n",
    "#     arcs = set()\n",
    "#     correct_arcs = {(arc.head, arc.dep) for arc in tree.arcs}\n",
    "    \n",
    "#     start_config = models.arc_standard.Configuration(stack, buffer, arcs)\n",
    "#     o = models.arc_standard.Oracle(start_config, correct_arcs)\n",
    "#     correct_sequence, configs_sequence = o.execute()\n",
    "# #     import pdb; pdb.set_trace()\n",
    "#     model_scores = []\n",
    "#     for i in correct_sequence:\n",
    "#         index = {\"left\": 0, \"right\": 1, \"shift\": 2}.get(i)\n",
    "#         dummy = [0, 0, 0]\n",
    "#         dummy[index] = 1\n",
    "#         model_scores.append(dummy)\n",
    "# #     import pdb; pdb.set_trace()\n",
    "# #     model_scores = [[0.3, 0.1, 0.6], [0.9, 0.05, 0.05],[0.2, 0.35, 0.45], [0.1, 0.2, 0.7], [0.1, 0.7, 0.2],[0.7, 0.1, 0.2]]  #[[left, right, shift]]\n",
    "#     arcstand = models.arc_standard.ArcStandard(start_config, model_scores ,correct_sequence)\n",
    "#     final_config = arcstand.execute()\n",
    "#     assert final_config.arcs == correct_arcs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = dp.template.Templates()\n",
    "temps.add_template(\"eisner\", \"unigram\", [\"hform\", \"hpos\", \"hform+hpos\", \"dform\", \"dpos\", \"dform+dpos\"])\n",
    "\n",
    "temps.add_template(\"eisner\", \"bigram\",['hform+hpos+dform+dpos', \"hpos+dform+dpos\", \"hform+dform+dpos\", \"hform+hpos+dform\",\n",
    "\"hform+hpos+dpos\", \"hform+dform\", \"hpos+dpos\"])\n",
    "\n",
    "temps.add_template(\"arc_standard\", \"nivre\", \n",
    "[\"S[0]-form\", \"S[0]-pos\",\"S[0]-lemma\" ,\"B[0]-form\",\"B[0]-lemma\", \"B[0]-pos\",\"B[1]-pos\",\n",
    " \"S[1]-pos\",\"ld(S[0])\",\"rd(S[0])\",\"ld(B[0])\",\"rd(B[0])\"])\n",
    "\n",
    "temps.add_template(\"arc_standard\", \"nivre_bigram\", [\"S[0]-form+S[0]-pos+B[0]-form+B[0]-pos\", \"S[0]-form+S[0]-pos+B[0]-form\",\n",
    "\"S[0]-form+B[0]-form+B[0]-pos\", \"S[0]-form+S[0]-pos+B[0]-pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['hform', 'hpos', 'hform+hpos', 'dform', 'dpos', 'dform+dpos'],\n",
       " ['hform+hpos+dform+dpos',\n",
       "  'hpos+dform+dpos',\n",
       "  'hform+dform+dpos',\n",
       "  'hform+hpos+dform',\n",
       "  'hform+hpos+dpos',\n",
       "  'hform+dform',\n",
       "  'hpos+dpos']]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "temps.get_algo_templates(\"eisner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_DEV_GOLD))\n",
    "\n",
    "dev_sentences = ds.sentences_from_splits(df_splits, test_sentence = False)\n",
    "dev_trees = [s.to_tree() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'start_config' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7643f663b04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m fe = dp.feature_extraction.FeatureExtraction([sentences[1]], [trees[1]], temps,\"arc_standard\" ,\n\u001b[1;32m      2\u001b[0m                                              \u001b[0muse_templates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"nivre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nivre_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                              configs = [[start_config]+configs_sequence])\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'start_config' is not defined"
     ]
    }
   ],
   "source": [
    "fe = dp.feature_extraction.FeatureExtraction([sentences[1]], [trees[1]], temps,\"arc_standard\" ,\n",
    "                                             use_templates = [\"nivre\", \"nivre_bigram\"],\n",
    "                                             configs = [[start_config]+configs_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 19, 20, 5, 21, 7, 8, 9, 23, 24, 29, 30, 31, 15]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.extract_feature_arcstandard(sentences[1], configs_sequence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16, 17, 18, 19, 20, 5, 21, 22, 8, 9, 23, 24, 25, 26, 27, 28],\n",
       " [0, 1, 2, 19, 20, 5, 21, 7, 8, 9, 23, 24, 29, 30, 31, 15],\n",
       " [32, 17, 33, 34, 35, 36, 6, 22, 37, 38, 23, 24, 39, 40, 41, 42],\n",
       " [0, 1, 2, 34, 35, 36, 6, 7, 8, 9, 23, 24, 43, 44, 45, 46],\n",
       " [47, 48, 49, 50, 51, 5, 52, 22, 37, 38, 10, 11, 53, 54, 55, 56],\n",
       " [0, 1, 2, 34, 35, 36, 52, 7, 8, 9, 23, 24, 43, 44, 45, 46],\n",
       " [47, 48, 49, 57, 58, 59, 60, 22, 37, 38, 10, 11, 61, 62, 63, 64],\n",
       " [0, 1, 2, 34, 35, 36, 60, 7, 37, 38, 23, 24, 43, 44, 45, 46],\n",
       " [65, 66, 67, 68, 69, 70, 60, 7, 8, 9, 23, 24, 71, 72, 73, 74],\n",
       " [0, 1, 2, 75, 76, 77, 60, 7, 37, 38, 10, 11, 71, 72, 73, 74]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.extract_feature_arcstandard_full(sentences[1], configs_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe = dp.feature_extraction.FeatureExtraction(sentences, trees, temps,\"eisner\" ,use_templates = [\"unigram\"],configs = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 60.36it/s]\n"
     ]
    }
   ],
   "source": [
    "eis = models.eisner.Eisner()\n",
    "potential_trees = eis.make_potential_trees(sentences)\n",
    "fe = dp.feature_extraction.FeatureExtraction(sentences[:10],\n",
    "                                             potential_trees, \n",
    "                                             temps,\n",
    "                                             \"eisner\",\n",
    "                                             use_templates = [\"unigram\",\n",
    "                                                              \"bigram\"\n",
    "                                                             ],\n",
    "                                             configs = None)\n",
    "# eis.fit(no_tokens, ml_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(fe.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = dp.evaluation.Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eisner_perceptron = models.eisner.EisnerPerceptron(vocab_size,\n",
    "                                                   eis,\n",
    "                                                   fe,\n",
    "                                                   eva,\n",
    "                                                   dev_gold_sentences = dev_sentences,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eisner_perceptron.train(sentences,\n",
    "#                         trees,\n",
    "#                         potential_trees,\n",
    "#                         epochs = 100,\n",
    "#                         path = dp.config.OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_potential_trees = eis.make_potential_trees(\n",
    "                dev_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1083/1083 [01:34<00:00, 11.43it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_trees = eisner_perceptron.test(dev_potential_trees, dev_gold_sentences=dev_sentences,\n",
    "                      load_from_path = dp.config.OUTPUT, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_TEST))\n",
    "\n",
    "dev_sentences = ds.sentences_from_splits(df_splits, test_sentence = False)\n",
    "dev_trees = [s.to_tree() for s in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_potential_trees = eis.make_potential_trees(\n",
    "                dev_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1382/1382 [01:53<00:00, 12.23it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_trees = eisner_perceptron.test(dev_potential_trees, dev_gold_sentences=dev_sentences,\n",
    "                       load_from_path = \"\", test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentences = [dev_sentences[i].get_head_info_from(predicted_trees[i]) for i in range(len(dev_sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits = ds.splits_from_sentences(predicted_sentences)\n",
    "\n",
    "dummy_splits = []\n",
    "for split in df_splits:\n",
    "    split[\"dummy1\"] = \"_\"\n",
    "    split[\"dummy2\"] = \"_\"\n",
    "    dummy_splits.append(split)\n",
    "\n",
    "predicted_sentences = [dev_sentences[i].get_head_info_from(predicted_trees[i]) for i in range(len(dev_sentences))]\n",
    "dl.to_conll(dp.config.OUTPUT / Path(\"english_prediction_test.conll06\"), dummy_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  Transition Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_TRAIN_1K))\n",
    "\n",
    "sentences = ds.sentences_from_splits(df_splits, test_sentence = False)\n",
    "trees = [s.to_tree() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dp.data_loader.DataLoader()\n",
    "ds = dp.dataset.Dataset()\n",
    "\n",
    "df_splits = dl.read_conll(Path(dp.config.ENG_DEV_GOLD))\n",
    "\n",
    "dev_sentences = ds.sentences_from_splits(df_splits, test_sentence = False)\n",
    "dev_trees = [s.to_tree() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sentences = [sentences[0]] * 1\n",
    "d_trees = [trees[0]] * 1\n",
    "\n",
    "# d_sentences = sentences[:100] * 10\n",
    "# d_trees = trees[:100] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = dp.template.Templates()\n",
    "template.add_template(\"arc_standard\", \"nivre\", \n",
    "[\"S[0]-form\", \"S[0]-pos\",\"S[0]-lemma\" ,\"B[0]-form\",\"B[0]-lemma\", \"B[0]-pos\",\"B[1]-pos\",\n",
    " \"S[1]-pos\",\"ld(S[0])\",\"rd(S[0])\",\"ld(B[0])\",\"rd(B[0])\"])\n",
    "template.add_template(\"arc_standard\", \"nivre_bigram\", [\"S[0]-form+S[0]-pos+B[0]-form+B[0]-pos\", \"S[0]-form+S[0]-pos+B[0]-form\",\n",
    "\"S[0]-form+B[0]-form+B[0]-pos\", \"S[0]-form+S[0]-pos+B[0]-pos\"])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcperceptron = models.arc_standard.ArcStandardPerceptron(evaluation = dp.evaluation.Evaluation(),\n",
    "                                                         dev_sentences = d_sentences\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = arcperceptron.train(sentences[:100],trees[:100], template, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}